{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMoO9ai7NDBlT69IRJLR+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurefindele-o-catto/ML-Projects/blob/main/CIFAR-10/Model%20using%20resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG0dQeDBS0UJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "zQbny3t5Zcyx",
        "outputId": "d469d6b5-269c-4e75-fa90-643ee2d9028e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**"
      ],
      "metadata": {
        "id": "1_4zJrG1JaMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_data(x, y, alpha = 0.1):\n",
        "  if alpha <= 0:\n",
        "    return x, y, y, 1.0\n",
        "\n",
        "  lam = np.random.beta(alpha, alpha)\n",
        "  batch_size = x.size(0)\n",
        "  index = torch.randperm(batch_size).to(x.device)\n",
        "  mixed_x = lam*x + (1-lam) * x[index, :]\n",
        "\n",
        "def cutmix_data(x, y, alpha = 1.0):\n",
        "  if alpha <= 0:\n",
        "    return x, y, y, 1.0\n",
        "\n",
        "  lam = np.random.beta(alpha, alpha)\n",
        "  batch_size, _, H, W = x.size()\n",
        "  index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "  cut_rat = np.sqrt(1. - lam)\n",
        "  cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
        "  cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "  x1, x2 = np.clip(cx - cut_w // 2, 0, W), np.clip(cx + cut_w // 2, 0, W)\n",
        "  y1, y2 = np.clip(cy - cut_h // 2, 0, H), np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "  x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "\n",
        "  lam = 1 - ((x2 - x1) * (y2-y1) / (W*H) )\n",
        "  y_a, y_b = y, y[index]\n",
        "\n",
        "  return x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
        "  return lam * criterion(pred, y_a) + (1 - lam)*criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "yLc8iCbBJcBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Using Resnet**"
      ],
      "metadata": {
        "id": "Ui80tGC8Zo2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4456)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.RandomCrop(32, padding = 4),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
        "])\n",
        "\n",
        "trainset = tv.datasets.CIFAR10(root='./data', train = True, download = True, transform = transform_train)\n",
        "testset = tv.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size = 256, shuffle = False, num_workers = 2, pin_memory = True)"
      ],
      "metadata": {
        "id": "Dcluv5ojaD9F",
        "outputId": "0c60deb9-83c8-4f9f-b1fa-2f1a7e40e372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 36.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Setup**"
      ],
      "metadata": {
        "id": "YlvAwesYcyhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(logits, targets):\n",
        "  return (logits.argmax(1) == targets).float().mean().item() * 100.0\n",
        "\n",
        "def train_resnet(model, train_loader, test_loader, epochs = 200, base_lr = 0.1, weight_decay = 5e-4, label_smoothing = 0.1, device = device):\n",
        "  model = model.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr = base_lr, momentum=0.9, weight_decay = weight_decay, nesterov = True)\n",
        "  scheduler = torch.optimc.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs, eta_min = base_lr*1e-2)\n",
        "\n",
        "  train_hist, test_hist = [], []\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total, correct, running = 0, 0, 0.0\n",
        "    for x, y in train_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      logits = model(x)\n",
        "      loss = criterion(logits, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running += loss.item() * x.size(0)\n",
        "      total += x.size(0)\n",
        "      correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    train_loss = running/total\n",
        "    train_acc = 100.0 * correct/total\n",
        "\n",
        "    model.eval()\n",
        "    total, correct, runnin = 0, 0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        running += loss.item() * x.size(0)\n",
        "        total += x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    test_loss = running/total\n",
        "    test_acc = 100.0*correct/total\n",
        "\n",
        "    scheduler.step()\n",
        "    train_hist.append(train_acc)\n",
        "    test_hist.append(test_acc)\n",
        "    print(f\"Epoch [{epoch:3d}/{epochs}] LR {scheduler.get_last_lr()[0]:.5f} | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "  return train_hist, test_hist"
      ],
      "metadata": {
        "id": "mxRMTjIRc_0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet_adv(model, train_loader, test_loader, epochs=200, base_lr=0.1,\n",
        "                     weight_decay=5e-4, label_smoothing=0.1,\n",
        "                     use_mixup=False, use_cutmix=False, alpha=1.0, device=None):\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9,\n",
        "                                weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=base_lr, epochs=epochs,\n",
        "        steps_per_epoch=len(train_loader), pct_start=0.1,\n",
        "        div_factor=25.0, final_div_factor=1e3\n",
        "    )\n",
        "\n",
        "    train_hist, test_hist = [], []\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total, correct = 0, 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Apply MixUp or CutMix\n",
        "            if use_mixup:\n",
        "                x, y_a, y_b, lam = mixup_data(x, y, alpha)\n",
        "            elif use_cutmix:\n",
        "                x, y_a, y_b, lam = cutmix_data(x, y, alpha)\n",
        "            else:\n",
        "                y_a, y_b, lam = y, y, 1.0\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = mixup_cutmix_criterion(criterion, logits, y_a, y_b, lam)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total += y.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "        train_acc = 100.0 * correct / total\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        total, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "                total += y.size(0)\n",
        "                correct += (logits.argmax(1) == y).sum().item()\n",
        "        test_acc = 100.0 * correct / total\n",
        "\n",
        "        train_hist.append(train_acc)\n",
        "        test_hist.append(test_acc)\n",
        "        print(f\"Epoch [{epoch:3d}/{epochs}] LR {scheduler.get_last_lr()[0]:.5f} | \"\n",
        "              f\"Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return train_hist, test_hist"
      ],
      "metadata": {
        "id": "tzfkeh6jldoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18_cifar(num_classes = 10)\n",
        "train_hist, test_hist = train_resnet(model, train_loader, test_loader, epochs = 100, base_lr=0/1)"
      ],
      "metadata": {
        "id": "8Rvy-k_yfee4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18_cifar()\n",
        "# MixUp\n",
        "train_hist, test_hist = train_resnet_adv(model, train_loader, test_loader,\n",
        "                                         epochs=100, base_lr=0.1,\n",
        "                                         use_mixup=True, alpha=1.0)\n",
        "\n",
        "# CutMix\n",
        "model = resnet18_cifar()\n",
        "train_hist, test_hist = train_resnet_adv(model, train_loader, test_loader,\n",
        "                                         epochs=100, base_lr=0.1,\n",
        "                                         use_cutmix=True, alpha=1.0)"
      ],
      "metadata": {
        "id": "3aSwKF3OlvDB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}