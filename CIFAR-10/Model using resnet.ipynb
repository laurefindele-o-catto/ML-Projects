{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkqH7o4R/G5tc9NA8X7tJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurefindele-o-catto/ML-Projects/blob/main/CIFAR-10/Model%20using%20resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WG0dQeDBS0UJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "zQbny3t5Zcyx",
        "outputId": "495b9064-562b-4ced-902d-eff13e67fa08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**"
      ],
      "metadata": {
        "id": "1_4zJrG1JaMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_data(x, y, alpha = 0.1):\n",
        "  if alpha <= 0:\n",
        "    return x, y, y, 1.0\n",
        "\n",
        "  lam = np.random.beta(alpha, alpha)\n",
        "  batch_size = x.size(0)\n",
        "  index = torch.randperm(batch_size).to(x.device)\n",
        "  mixed_x = lam*x + (1-lam) * x[index, :]\n",
        "\n",
        "def cutmix_data(x, y, alpha = 1.0):\n",
        "  if alpha <= 0:\n",
        "    return x, y, y, 1.0\n",
        "\n",
        "  lam = np.random.beta(alpha, alpha)\n",
        "  batch_size, _, H, W = x.size()\n",
        "  index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "  cut_rat = np.sqrt(1. - lam)\n",
        "  cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
        "  cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "  x1, x2 = np.clip(cx - cut_w // 2, 0, W), np.clip(cx + cut_w // 2, 0, W)\n",
        "  y1, y2 = np.clip(cy - cut_h // 2, 0, H), np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "  x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "\n",
        "  lam = 1 - ((x2 - x1) * (y2-y1) / (W*H) )\n",
        "  y_a, y_b = y, y[index]\n",
        "\n",
        "  return x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
        "  return lam * criterion(pred, y_a) + (1 - lam)*criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "yLc8iCbBJcBi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Using Resnet**"
      ],
      "metadata": {
        "id": "Ui80tGC8Zo2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "  def __init__(self, in_ch, out_ch, stride = 1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride = stride, padding = 1, bias  = False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "    self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "    self.downsample = None\n",
        "    if stride != 1 or in_ch != out_ch:\n",
        "      self.downsample = nn.Sequential(\n",
        "          nn.Conv2d(in_ch, out_ch, kerner_size = 1, stride = stride, bias = False),\n",
        "          nn.BatchNorm2d(out_ch)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x  #save input for skip connection\n",
        "\n",
        "    out = F.relu(self.bn1(self.conv1(x)), inplace = True)\n",
        "    out = self.bn2(self.conv2(out))\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    out = F.relu(out + identity, inplace = True)  #residual connection\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "3SZysPdqnEjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " class ResNet_CIFAR(nn.Module):\n",
        "    def __init__(self, block=BasicBlock, layers=(2,2,2,2), num_classes=10):\n",
        "        super().__init__()\n",
        "        # CIFAR stem: 3x3 conv, stride 1, no maxpool\n",
        "        self.in_ch = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64,  layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, out_ch, blocks, stride):\n",
        "        layers = [block(self.in_ch, out_ch, stride)]\n",
        "        self.in_ch = out_ch * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_ch, out_ch, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)\n",
        "\n",
        "def resnet18_cifar(num_classes=10):\n",
        "    return ResNet_CIFAR(BasicBlock, (2,2,2,2), num_classes)"
      ],
      "metadata": {
        "id": "N9qubo6YnxNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4456)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "transform_train = T.Compose([\n",
        "    T.RandomCrop(32, padding = 4),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
        "])\n",
        "\n",
        "transform_test = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
        "])\n",
        "\n",
        "trainset = tv.datasets.CIFAR10(root='./data', train = True, download = True, transform = transform_train)\n",
        "testset = tv.datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size = 256, shuffle = False, num_workers = 2, pin_memory = True)"
      ],
      "metadata": {
        "id": "Dcluv5ojaD9F",
        "outputId": "c5653371-eb7e-4315-fa7f-f30ecf90bf5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Setup**"
      ],
      "metadata": {
        "id": "YlvAwesYcyhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(logits, targets):\n",
        "  return (logits.argmax(1) == targets).float().mean().item() * 100.0\n",
        "\n",
        "def train_resnet(model, train_loader, test_loader, epochs = 200, base_lr = 0.1, weight_decay = 5e-4, label_smoothing = 0.1, device = device):\n",
        "  model = model.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr = base_lr, momentum=0.9, weight_decay = weight_decay, nesterov = True)\n",
        "  scheduler = torch.optimc.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs, eta_min = base_lr*1e-2)\n",
        "\n",
        "  train_hist, test_hist = [], []\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total, correct, running = 0, 0, 0.0\n",
        "    for x, y in train_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      logits = model(x)\n",
        "      loss = criterion(logits, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running += loss.item() * x.size(0)\n",
        "      total += x.size(0)\n",
        "      correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    train_loss = running/total\n",
        "    train_acc = 100.0 * correct/total\n",
        "\n",
        "    model.eval()\n",
        "    total, correct, runnin = 0, 0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        running += loss.item() * x.size(0)\n",
        "        total += x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    test_loss = running/total\n",
        "    test_acc = 100.0*correct/total\n",
        "\n",
        "    scheduler.step()\n",
        "    train_hist.append(train_acc)\n",
        "    test_hist.append(test_acc)\n",
        "    print(f\"Epoch [{epoch:3d}/{epochs}] LR {scheduler.get_last_lr()[0]:.5f} | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "  return train_hist, test_hist"
      ],
      "metadata": {
        "id": "mxRMTjIRc_0u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet_adv(model, train_loader, test_loader, epochs=200, base_lr=0.1,\n",
        "                     weight_decay=5e-4, label_smoothing=0.1,\n",
        "                     use_mixup=False, use_cutmix=False, alpha=1.0, device=None):\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9,\n",
        "                                weight_decay=weight_decay, nesterov=True)\n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    #     optimizer, max_lr=base_lr, epochs=epochs,\n",
        "    #     steps_per_epoch=len(train_loader), pct_start=0.1,\n",
        "    #     div_factor=25.0, final_div_factor=1e3\n",
        "    # )\n",
        "\n",
        "    scheduler = torch.optimc.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs, eta_min = base_lr*1e-2)\n",
        "\n",
        "\n",
        "    train_hist, test_hist = [], []\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total, correct = 0, 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            #to randomize\n",
        "            if use_mixup and use_cutmix:\n",
        "                choice = random.choice([\"mixup\", \"cutmix\", \"none\"])\n",
        "            elif use_mixup:\n",
        "                choice = \"mixup\"\n",
        "            elif use_cutmix:\n",
        "                choice = \"cutmix\"\n",
        "            else:\n",
        "                choice = \"none\"\n",
        "\n",
        "            # Apply MixUp or CutMix\n",
        "            if use_mixup:\n",
        "                x, y_a, y_b, lam = mixup_data(x, y, alpha)\n",
        "            elif use_cutmix:\n",
        "                x, y_a, y_b, lam = cutmix_data(x, y, alpha)\n",
        "            else:\n",
        "                y_a, y_b, lam = y, y, 1.0\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = mixup_cutmix_criterion(criterion, logits, y_a, y_b, lam)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total += y.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "        train_acc = 100.0 * correct / total\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        total, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "                total += y.size(0)\n",
        "                correct += (logits.argmax(1) == y).sum().item()\n",
        "        test_acc = 100.0 * correct / total\n",
        "\n",
        "        train_hist.append(train_acc)\n",
        "        test_hist.append(test_acc)\n",
        "        print(f\"Epoch [{epoch:3d}/{epochs}] LR {scheduler.get_last_lr()[0]:.5f} | \"\n",
        "              f\"Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return train_hist, test_hist"
      ],
      "metadata": {
        "id": "tzfkeh6jldoN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18_cifar(num_classes = 10)\n",
        "train_hist, test_hist = train_resnet(model, train_loader, test_loader, epochs = 100, base_lr=0/1)"
      ],
      "metadata": {
        "id": "8Rvy-k_yfee4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18_cifar()\n",
        "# Randomize CutMix and MixUp\n",
        "train_hist, test_hist = train_resnet_adv(model, train_loader, test_loader,\n",
        "                                         epochs=100, base_lr=0.1,\n",
        "                                         use_mixup=True, use_cutmix=True, alpha=1.0)"
      ],
      "metadata": {
        "id": "3aSwKF3OlvDB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}